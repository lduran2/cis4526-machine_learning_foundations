{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",

   "metadata": {},
   "source": [
    "The data is stored in `3` files.\n",
    "1. `train.csv` numbers `18,304` samples and contains the training data including features and labels. \n",
    "2. `test.csv` numbers `4580` samples and contains the testing feature without labels.\n",
    "3. `sample.csv` number `4580` samples and contains the testing labels without features.\n",
    "\n",
    "Every file has table headers and ends in an empty line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r'dataset-in/'   # directory holding the data files\n",
    "# names of files holding dataset\n",
    "DATA_FILENAMES = {\\\n",
    "                  r'trainXy': r'train.csv',\\\n",
    "                  r'testX':   r'test.csv',\\\n",
    "                  r'test_y':  r'sample.csv',\\\n",
    "                 }\n",
    "DELIMITER = r','    # used to separate values in DATA_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for datatype, file in DATA_FILENAMES.items():\n",
    "    data[datatype] = np.genfromtxt(\n",
    "        fr'{DATA_DIR}{file}', delimiter=DELIMITER,\n",
    "        skip_header=True, dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "markdown",

   "metadata": {},
   "source": [
    "Let's count the number of samples as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainXy \t   18304\n",
      "testX   \t    4580\n",
      "test_y  \t    4580\n"
     ]
    }
   ],
   "source": [
    "for datatype, array in data.items():\n",
    "    print(f'{datatype:8}\\t{len(array):8}')"
   ]
  },
  {
   "cell_type": "markdown",

   "metadata": {},
   "source": [
    "We can assume that the IDs are succeeding in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trainXy': True, 'testX': True, 'test_y': True}\n"
     ]
    }
   ],
   "source": [
    "isSorted = {}\n",
    "for datatype, array in data.items():\n",
    "    isSorted[datatype] = True\n",
    "    for irow in range(1, array.shape[0]):\n",
    "        if (int(array[irow, 0]) != (int(array[(irow - 1), 0]) + 1)):\n",
    "            isSorted[datatype] = False\n",
    "            break\n",
    "print(isSorted)"
   ]
  },
  {
   "cell_type": "markdown",

   "metadata": {},
   "source": [
    "Let's split `trainXy` into features and labels resembling `testX` and `test_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18304, 12)\n",
      "[(4535, 11), (4535,)]\n"
     ]
    }
   ],
   "source": [
    "def splitFeaturesLabels(dataset, classify):\n",
    "    r'''\n",
    "     Divides the dataset into features and labels.\n",
    "     @param dataset : 'numpy.ndarray' = the dataset to divide\n",
    "     @param classify : 'function' = label classifier function\n",
    "     @return a tuple containing the features and the labels\n",
    "     '''\n",
    "    # get the number of rows and columns\n",
    "    (num_rows, num_cols) = dataset.shape\n",
    "\n",
    "    # divide into features and labels\n",
    "    # function to classify the label scalars\n",
    "    vec_classify = np.vectorize(classify)\n",
    "    # split the dataset\n",
    "    (unvalid_features, M_label_scalars) = \\\n",
    "        np.split(dataset, (num_cols - 1,), axis=1)\n",
    "    # convert to a vector\n",
    "    v_label_scalars = M_label_scalars.reshape((num_rows,))\n",
    "    # classify the labels\n",
    "    unvalid_labels = vec_classify(v_label_scalars)\n",
    "\n",
    "    # remove all 0 rows\n",
    "    # 0 rows are when the label scalar is neither in [7..10[ nor [3..6[\n",
    "    should_keep_rows = (unvalid_labels != 0)\n",
    "    features = unvalid_features[should_keep_rows,:]\n",
    "    labels = unvalid_labels[should_keep_rows]\n",
    "\n",
    "    return (features, labels)\n",
    "# end def splitFeaturesLabels(dataset)\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "# print the shape of trainXy before splitting\n",
    "print(data['trainXy'].shape)\n",
    "# print the shape of each after splitting\n",
    "print([x.shape for x in splitFeaturesLabels(data['trainXy'], identity)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
